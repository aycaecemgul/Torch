{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMU/C9+51NH/eqWQuuD5JeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aycaecemgul/Torch/blob/main/torch_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚡ **Pytorch 101** ⚡\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-01JXUQB71sR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "9JKyWmfi6Yju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing a tensor"
      ],
      "metadata": {
        "id": "WSduUbrk43Ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#directly from data\n",
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "G3uIMHLT417f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from another tensor\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data"
      ],
      "metadata": {
        "id": "iDC5Rohk5Akk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attributes of tensor\n",
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "2ohCAvy85afq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#With random or constant values\n",
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)"
      ],
      "metadata": {
        "id": "1SYc5YP15RKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulating Tensor Shapes"
      ],
      "metadata": {
        "id": "1jHkBGWp110k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unsqueeze() method adds a dimension of extent 1. unsqueeze(0) adds it as a new zeroth dimension - now you have a batch of one!"
      ],
      "metadata": {
        "id": "5Cxs_B6r2A4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(3, 226, 226)\n",
        "b = a.unsqueeze(0)\n",
        "\n",
        "#out:\n",
        "# torch.Size([3, 226, 226])\n",
        "# torch.Size([1, 3, 226, 226])"
      ],
      "metadata": {
        "id": "AymU15pS11cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuing the example above, let’s say the model’s output is a 20-element vector for each input. You would then expect the output to have shape (N, 20), where N is the number of instances in the input batch. That means that for our single-input batch, we’ll get an output of shape (1, 20).\n",
        "\n",
        "What if you want to do some non-batched computation with that output - something that’s just expecting a 20-element vector?"
      ],
      "metadata": {
        "id": "kurRucmC2Mxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.rand(2, 2)\n",
        "print(c.shape)\n",
        "\n",
        "d = c.squeeze(0)\n",
        "print(d.shape)"
      ],
      "metadata": {
        "id": "2rwtKqOG0cp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "n-dimentional tensor to 1 dimention tensor"
      ],
      "metadata": {
        "id": "qnCKoRZl4HfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output3d = torch.rand(6, 20, 20)\n",
        "print(output3d.shape)\n",
        "\n",
        "input1d = output3d.reshape(6 * 20 * 20)\n",
        "print(input1d.shape)\n"
      ],
      "metadata": {
        "id": "r6CmpIZj2Okx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy to torch"
      ],
      "metadata": {
        "id": "65A-qGsc4RFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numpy_array = np.ones((2, 3))\n",
        "print(numpy_array)\n",
        "\n",
        "pytorch_tensor = torch.from_numpy(numpy_array)\n",
        "print(pytorch_tensor)"
      ],
      "metadata": {
        "id": "JWQfzHNj4giM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch to numpy"
      ],
      "metadata": {
        "id": "V4KQDUqT4jC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_rand = torch.rand(2, 3)\n",
        "print(pytorch_rand)\n",
        "\n",
        "numpy_rand = pytorch_rand.numpy()\n",
        "print(numpy_rand)"
      ],
      "metadata": {
        "id": "IoevvgI54iqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Data & Datasets"
      ],
      "metadata": {
        "id": "-BqybHlQb-yF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPcpjxv4bvhj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch has two primitives to work with data: **torch.utils.data.DataLoader** and **torch.utils.data.Dataset**. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.\n",
        "The **torchvision.datasets **module contains Dataset objects for many real-world vision data like CIFAR, COCO"
      ],
      "metadata": {
        "id": "W6uQhdLzb8uB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**root** is the path where the train/test data is stored,\n",
        "**train** specifies training or test dataset,\n",
        "**download=True** downloads the data from the internet if it’s not available at root.\n",
        "**transform** and **target_transform **specify the feature and label transformations"
      ],
      "metadata": {
        "id": "PP4yuE6gc_7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "ETWgZVuib8Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoader** wraps an iterable over our dataset, and supports a**utomatic batching, sampling, shuffling and multiprocess data loading**. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
      ],
      "metadata": {
        "id": "G9XcrK1McdV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "a03r2o-qcSGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a custom dataset for your files"
      ],
      "metadata": {
        "id": "jxuM1BMmdKZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom Dataset class must implement three functions: __init__, __len__, and __getitem__.\n",
        "\n",
        "images are stored in a directory img_dir, and their labels are stored separately in a CSV file annotations_file"
      ],
      "metadata": {
        "id": "8woVQKvZdUfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform #transform methods for images\n",
        "        self.target_transform = target_transform #transform methods for labels\n",
        "\n",
        "    #returns the number of samples \n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "    \n",
        "    #returns image on a given id\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "41lhlJ_lcsqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Each iteration below returns a batch of **train_features** and **train_labels** **(containing batch_size=64 features and labels respectively)**. Because we specified **shuffle=True**, after we iterate over all batches the data is shuffled"
      ],
      "metadata": {
        "id": "hiwDVi5NgEhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "AL2ct9zldbGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "CO2P_bfggSeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Models\n"
      ],
      "metadata": {
        "id": "tyR5rH0Ug35m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To define a neural network in PyTorch, we create a class that inherits from** nn.Module** We define the layers of the network in the __init__ function and specify how data will pass through the network in the **forward** function."
      ],
      "metadata": {
        "id": "BIhxX4iUg9S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "        \n",
        "    #connect layers using forward\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "gRutaz4Ug1CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Optimizing the Model Parameters"
      ],
      "metadata": {
        "id": "H0F-X7eDhauT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **gradient** is a vector which gives us the direction in which loss function has the steepest ascent. Exactly opposite to the direction of the gradient is which we have to move in.(moving along which direction brings about the steepest decline in the value of the loss function) We perform **descent** along the direction of the gradient, hence, it's called **Gradient Descent**. Now, once we have the direction we want to move in, we must decide the size of the step we must take. The the size of this step is called the **learning rate**. We must chose it carefully to ensure we can get down to the minima. **Once we have our gradient and the learning rate, we take a step, and recompute the gradient at whatever position we end up at, and repeat the process.**"
      ],
      "metadata": {
        "id": "NJVL4OpWju0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step()** makes the optimizer iterate over all parameters (tensors) it is supposed to update and use their internally stored grad to update their values.\n",
        "\n",
        "\n",
        "When you create a tensor, if you set its attribute .requires_grad as True, the package tracks all operations on it. This happens on subsequent backward passes. The gradient for this tensor will be accumulated into .grad attribute. The accumulation (or sum) of all the gradients is calculated when .backward() is called on the loss tensor."
      ],
      "metadata": {
        "id": "icuR9gaIiiCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y) # Compute prediction error\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "xN3xa-Vlhn1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the direction of the gradient tells us which direction has the steepest ascent, it's magnitude tells us how steep the steepest ascent/descent is. So, at the minima, where the contour is almost flat, you would expect the gradient to be almost zero. In fact, it's precisely zero for the point of minima."
      ],
      "metadata": {
        "id": "acS3gIFGnXKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We subtract the gradient of the loss function with respect to the weights multiplied by alpha, the learning rate. The gradient is a vector which gives us the direction in which loss function has the steepest ascent. The direction of steepest descent is the direction exactly opposite to the gradient, and that is why we are subtracting the gradient vector from the weights vector. Before subtracting we multiply the gradient vector by the learning rate. "
      ],
      "metadata": {
        "id": "g_u8MQ_3nuSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can afford a large learning rate. But later on, we want to slow down as we approach a minima. An approach that implements this strategy is called **Simulated annealing, or decaying learning rate.** In this, the learning rate is decayed every fixed number of iterations."
      ],
      "metadata": {
        "id": "Y1re4rxjoIoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent is driven by the gradient, which will be zero at the base of any minima. Local minimum are called so since the value of the loss function is minimum at that point in a local region. Whereas, a global minima is called so since the value of the loss function is minimum there, globally across the entire domain the loss function."
      ],
      "metadata": {
        "id": "m14rRBauogqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A way to help GD escape saddle point is to use what is called Stochastic Gradient Descent.  instead of taking a step by computing the gradient of the loss function creating by summing all the loss functions, we take a step by computing the gradient of the loss of only one randomly sampled example. from a theoretical standpoint, stochastic gradient descent might give us the best results, it's not a very viable option. So, what we do is a balancing act. Instead of using the entire dataset, or just a single example to construct our loss function, we use a fixed number of examples say, 16, 32 or 128 to form what is called a mini-batch. The word is used in contrast with processing all the examples at once, which is generally called Batch Gradient Descent. \n"
      ],
      "metadata": {
        "id": "ClMQZMjapNYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use an optimizer\n"
      ],
      "metadata": {
        "id": "83RS0QcV65OU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use torch.optim you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients.\n",
        "To construct an Optimizer you have to give it an iterable containing the parameters (all should be Variable s) to optimize. Then, you can specify optimizer-specific options such as the learning rate, weight decay, etc."
      ],
      "metadata": {
        "id": "PYbILuKIrh8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam([var1, var2], lr=0.0001)"
      ],
      "metadata": {
        "id": "epaoRBGFnV6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer s also support specifying per-parameter options. To do this, instead of passing an iterable of Variable s, pass in an iterable of dict s. Each of them will define a separate parameter group, and should contain a params key, containing a list of parameters belonging to it. Other keys should match the keyword arguments accepted by the optimizers, and will be used as optimization options for this group."
      ],
      "metadata": {
        "id": "lX1UL0xDrrLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that model.base’s parameters will use the default learning rate of 1e-2, model.classifier’s parameters will use a learning rate of 1e-3, and a momentum of 0.9 will be used for all parameters."
      ],
      "metadata": {
        "id": "nWTXgIgSsBgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "optim.SGD([\n",
        "                {'params': model.base.parameters()},\n",
        "                {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
        "            ], lr=1e-2, momentum=0.9)"
      ],
      "metadata": {
        "id": "V6tVpHxTrxNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All optimizers implement a step() method, that updates the parameters. It can be used in two ways:\n",
        "\n",
        "optimizer.step()\n",
        "This is a simplified version supported by most optimizers. The function can be called once the gradients are computed using e.g. backward()."
      ],
      "metadata": {
        "id": "ycBLByLesOae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Otherwise, the gradient would be a combination of the old gradient, which you have already used to update your model parameters, and the newly-computed gradient. It would therefore point in some other direction than the intended direction towards the minimum"
      ],
      "metadata": {
        "id": "7ddoXELNt2Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accumulation (or sum) of all the gradients is calculated when .backward() is called on the loss tensor. There are cases where it may be necessary to zero-out the gradients of a tensor. For example: when you start your training loop, you should zero out the gradients so that you can perform this tracking correctly."
      ],
      "metadata": {
        "id": "pHMJyLSfuDrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target in dataset:\n",
        "    optimizer.zero_grad()\n",
        "    # Compute prediction error\n",
        "    pred = model(input)\n",
        "    loss = loss_fn(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "u7RfsuY-sNw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use model.zero_grad(). This is the same as using optimizer.zero_grad() as long as all your model parameters are in that optimizer."
      ],
      "metadata": {
        "id": "ZKn2hSn6wdRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "vLjMeVqQwvc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "pO3h3SOKwvxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "ApXso6LMw2U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model"
      ],
      "metadata": {
        "id": "GugPgjrQw9Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "TWP5tZ88w703"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the model\n",
        "\n",
        "The process for loading a model includes re-creating the model structure and loading the state dictionary into it.\n",
        "\n"
      ],
      "metadata": {
        "id": "6O7IkkK6xAxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "id": "B4rXHxFQxCXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "uy-ocHyMxHyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "id": "45vV34uDxIrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforms"
      ],
      "metadata": {
        "id": "Wm3K1NZjzsW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "transforms.ToTensor() converts images loaded by Pillow into PyTorch tensors.\n",
        "transforms.Normalize() adjusts the values of the tensor so that their average is zero and their standard deviation is 0.5. Most activation functions have their strongest gradients around x = 0, so centering our data there can speed learning."
      ],
      "metadata": {
        "id": "Vq4WbWdBzv7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moving to GPU"
      ],
      "metadata": {
        "id": "T_TSe0Lf7vMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the major advantages of PyTorch is its robust acceleration on CUDA-compatible Nvidia GPUs. (“CUDA” stands for Compute Unified Device Architecture, which is Nvidia’s platform for parallel computing.) So far, everything we’ve done has been on CPU."
      ],
      "metadata": {
        "id": "l3EWLoZf0MFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('We have a GPU!')\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ],
      "metadata": {
        "id": "oIEd0NaA0QY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we’ve determined that one or more GPUs is available, we need to put our data someplace where the GPU can see it. Your CPU does computation on data in your computer’s RAM. Your GPU has dedicated memory attached to it. Whenever you want to perform a computation on a device, you must move all the data needed for that computation to memory accessible by that device. By default, new tensors are created on the CPU, so we have to specify when we want to create our tensor on the GPU with the optional **device** argument. in order to do computation involving two or more tensors, all of the tensors must be on the same device. "
      ],
      "metadata": {
        "id": "yi4mxtkvzwu-"
      }
    }
  ]
}